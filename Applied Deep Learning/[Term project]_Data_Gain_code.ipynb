{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Deep Learning Term Project\n",
    "\n",
    "### Data gain code\n",
    "\n",
    "- Python code & result\n",
    "\n",
    "- Hae-yong Joung (2019311266)\n",
    "\n",
    "- - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import os\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from html_table_parser import parser_functions as parser\n",
    "import numpy as np\n",
    "import csv\n",
    "from konlpy.tag import Twitter \n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import theano\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import sys, re\n",
    "import pandas as pd\n",
    "import csv\n",
    "import getpass\n",
    "import gensim\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Conv1D, Conv2D,Convolution2D, MaxPooling2D, MaxPooling1D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape, merge\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "okt = Okt()\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\Users\\\\JYW\\\\OneDrive - 연세대학교 (Yonsei University)\\\\정해용\\\\2020 1학기\\\\딥러닝응용\\\\project')\n",
    "# should change the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Gain\n",
    "\n",
    "- Gain data from the naver newpaper article by keyword using crawling\n",
    "- keyword: *기아타이거즈*\n",
    "- period: 2019.04 ~ 09\n",
    "- number: Maximum 100 articles for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword is  타이거즈\n",
      "Month list:  ['2019.04.', '2019.05.', '2019.06.', '2019.07.', '2019.08.', '2019.09.']\n"
     ]
    }
   ],
   "source": [
    "keyword = '타이거즈'\n",
    "whole_source = \"\"\n",
    "\n",
    "date_dict = {'2019.04.': range(0,30),'2019.05.': range(0,31),'2019.06.': range(0,30),'2019.07.': range(0,31),\n",
    "             '2019.08.': range(0,31),'2019.09.': range(0,30)}\n",
    "\n",
    "print(\"Keyword is \", keyword)\n",
    "print(\"Month list: \", list(date_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.04.01 : 11 articles are done\n",
      "2019.04.02 : 19 articles are done\n",
      "2019.04.03 : 17 articles are done\n",
      "2019.04.04 : 19 articles are done\n",
      "2019.04.05 : 23 articles are done\n",
      "2019.04.06 : 15 articles are done\n",
      "2019.04.07 : 17 articles are done\n",
      "2019.04.08 : 10 articles are done\n",
      "2019.04.09 : 17 articles are done\n",
      "2019.04.10 : 22 articles are done\n",
      "2019.04.11 : 12 articles are done\n",
      "2019.04.12 : 14 articles are done\n",
      "2019.04.13 : 20 articles are done\n",
      "2019.04.14 : 36 articles are done\n",
      "2019.04.15 : 14 articles are done\n",
      "2019.04.16 : 24 articles are done\n",
      "2019.04.17 : 19 articles are done\n",
      "2019.04.18 : 14 articles are done\n",
      "2019.04.19 : 21 articles are done\n",
      "2019.04.20 : 11 articles are done\n",
      "2019.04.21 : 21 articles are done\n",
      "2019.04.22 : 18 articles are done\n",
      "2019.04.23 : 20 articles are done\n",
      "2019.04.24 : 16 articles are done\n",
      "2019.04.25 : 28 articles are done\n",
      "2019.04.26 : 18 articles are done\n",
      "2019.04.27 : 32 articles are done\n",
      "2019.04.28 : 16 articles are done\n",
      "2019.04.29 : 10 articles are done\n",
      "2019.04.30 : 39 articles are done\n",
      "2019.04. : 573 articles are available\n",
      "---------------------------------------------------\n",
      "2019.05.01 : 22 articles are done\n",
      "2019.05.02 : 19 articles are done\n",
      "2019.05.03 : 10 articles are done\n",
      "2019.05.04 : 6 articles are done\n",
      "2019.05.05 : 15 articles are done\n",
      "2019.05.06 : 10 articles are done\n",
      "2019.05.07 : 19 articles are done\n",
      "2019.05.08 : 7 articles are done\n",
      "2019.05.09 : 12 articles are done\n",
      "2019.05.10 : 18 articles are done\n",
      "2019.05.11 : 13 articles are done\n",
      "2019.05.12 : 23 articles are done\n",
      "2019.05.13 : 19 articles are done\n",
      "2019.05.14 : 31 articles are done\n",
      "2019.05.15 : 29 articles are done\n",
      "2019.05.16 : 37 articles are done\n",
      "2019.05.17 : 30 articles are done\n",
      "2019.05.18 : 16 articles are done\n",
      "2019.05.19 : 26 articles are done\n",
      "2019.05.20 : 15 articles are done\n",
      "2019.05.21 : 26 articles are done\n",
      "2019.05.22 : 33 articles are done\n",
      "2019.05.23 : 34 articles are done\n",
      "2019.05.24 : 28 articles are done\n",
      "2019.05.25 : 21 articles are done\n",
      "2019.05.26 : 28 articles are done\n",
      "2019.05.27 : 31 articles are done\n",
      "2019.05.28 : 27 articles are done\n",
      "2019.05.29 : 30 articles are done\n",
      "2019.05.30 : 23 articles are done\n",
      "2019.05.31 : 15 articles are done\n",
      "2019.05. : 673 articles are available\n",
      "---------------------------------------------------\n",
      "2019.06.01 : 11 articles are done\n",
      "2019.06.02 : 11 articles are done\n",
      "2019.06.03 : 13 articles are done\n",
      "2019.06.04 : 21 articles are done\n",
      "2019.06.05 : 23 articles are done\n",
      "2019.06.06 : 27 articles are done\n",
      "2019.06.07 : 13 articles are done\n",
      "2019.06.08 : 15 articles are done\n",
      "2019.06.09 : 14 articles are done\n",
      "2019.06.10 : 7 articles are done\n",
      "2019.06.11 : 27 articles are done\n",
      "2019.06.12 : 16 articles are done\n",
      "2019.06.13 : 21 articles are done\n",
      "2019.06.14 : 8 articles are done\n",
      "2019.06.15 : 14 articles are done\n",
      "2019.06.16 : 11 articles are done\n",
      "2019.06.17 : 9 articles are done\n",
      "2019.06.18 : 31 articles are done\n",
      "2019.06.19 : 27 articles are done\n",
      "2019.06.20 : 16 articles are done\n",
      "2019.06.21 : 19 articles are done\n",
      "2019.06.22 : 17 articles are done\n",
      "2019.06.23 : 16 articles are done\n",
      "2019.06.24 : 20 articles are done\n",
      "2019.06.25 : 13 articles are done\n",
      "2019.06.26 : 30 articles are done\n",
      "2019.06.27 : 18 articles are done\n",
      "2019.06.28 : 11 articles are done\n",
      "2019.06.29 : 18 articles are done\n",
      "2019.06.30 : 24 articles are done\n",
      "2019.06. : 521 articles are available\n",
      "---------------------------------------------------\n",
      "2019.07.01 : 14 articles are done\n",
      "2019.07.02 : 20 articles are done\n",
      "2019.07.03 : 27 articles are done\n",
      "2019.07.04 : 18 articles are done\n",
      "2019.07.05 : 24 articles are done\n",
      "2019.07.06 : 40 articles are done\n",
      "2019.07.07 : 23 articles are done\n",
      "2019.07.08 : 15 articles are done\n",
      "2019.07.09 : 22 articles are done\n",
      "2019.07.10 : 10 articles are done\n",
      "2019.07.11 : 9 articles are done\n",
      "2019.07.12 : 17 articles are done\n",
      "2019.07.13 : 20 articles are done\n",
      "2019.07.14 : 18 articles are done\n",
      "2019.07.15 : 10 articles are done\n",
      "2019.07.16 : 15 articles are done\n",
      "2019.07.17 : 20 articles are done\n",
      "2019.07.18 : 12 articles are done\n",
      "2019.07.19 : 8 articles are done\n",
      "2019.07.20 : 1 articles are done\n",
      "2019.07.21 : 4 articles are done\n",
      "2019.07.22 : 8 articles are done\n",
      "2019.07.23 : 8 articles are done\n",
      "2019.07.24 : 3 articles are done\n",
      "2019.07.25 : 5 articles are done\n",
      "2019.07.26 : 14 articles are done\n",
      "2019.07.27 : 13 articles are done\n",
      "2019.07.28 : 13 articles are done\n",
      "2019.07.29 : 9 articles are done\n",
      "2019.07.30 : 22 articles are done\n",
      "2019.07.31 : 24 articles are done\n",
      "2019.07. : 466 articles are available\n",
      "---------------------------------------------------\n",
      "2019.08.01 : 24 articles are done\n",
      "2019.08.02 : 4 articles are done\n",
      "2019.08.03 : 4 articles are done\n",
      "2019.08.04 : 14 articles are done\n",
      "2019.08.05 : 8 articles are done\n",
      "2019.08.06 : 20 articles are done\n",
      "2019.08.07 : 20 articles are done\n",
      "2019.08.08 : 23 articles are done\n",
      "2019.08.09 : 10 articles are done\n",
      "2019.08.10 : 21 articles are done\n",
      "2019.08.11 : 12 articles are done\n",
      "2019.08.12 : 13 articles are done\n",
      "2019.08.13 : 24 articles are done\n",
      "2019.08.14 : 19 articles are done\n",
      "2019.08.15 : 21 articles are done\n",
      "2019.08.16 : 9 articles are done\n",
      "2019.08.17 : 7 articles are done\n",
      "2019.08.18 : 14 articles are done\n",
      "2019.08.19 : 9 articles are done\n",
      "2019.08.20 : 11 articles are done\n",
      "2019.08.21 : 12 articles are done\n",
      "2019.08.22 : 13 articles are done\n",
      "2019.08.23 : 16 articles are done\n",
      "2019.08.24 : 7 articles are done\n",
      "2019.08.25 : 14 articles are done\n",
      "2019.08.26 : 19 articles are done\n",
      "2019.08.27 : 19 articles are done\n",
      "2019.08.28 : 19 articles are done\n",
      "2019.08.29 : 16 articles are done\n",
      "2019.08.30 : 15 articles are done\n",
      "2019.08.31 : 7 articles are done\n",
      "2019.08. : 444 articles are available\n",
      "---------------------------------------------------\n",
      "2019.09.01 : 23 articles are done\n",
      "2019.09.02 : 11 articles are done\n",
      "2019.09.03 : 8 articles are done\n",
      "2019.09.04 : 16 articles are done\n",
      "2019.09.05 : 15 articles are done\n",
      "2019.09.06 : 13 articles are done\n",
      "2019.09.07 : 12 articles are done\n",
      "2019.09.08 : 14 articles are done\n",
      "2019.09.09 : 10 articles are done\n",
      "2019.09.10 : 16 articles are done\n",
      "2019.09.11 : 20 articles are done\n",
      "2019.09.12 : 13 articles are done\n",
      "2019.09.13 : 13 articles are done\n",
      "2019.09.14 : 11 articles are done\n",
      "2019.09.15 : 3 articles are done\n",
      "2019.09.16 : 4 articles are done\n",
      "2019.09.17 : 30 articles are done\n",
      "2019.09.18 : 37 articles are done\n",
      "2019.09.19 : 27 articles are done\n",
      "2019.09.20 : 13 articles are done\n",
      "2019.09.21 : 14 articles are done\n",
      "2019.09.22 : 6 articles are done\n",
      "2019.09.23 : 19 articles are done\n",
      "2019.09.24 : 30 articles are done\n",
      "2019.09.25 : 12 articles are done\n",
      "2019.09.26 : 22 articles are done\n",
      "2019.09.27 : 11 articles are done\n",
      "2019.09.28 : 15 articles are done\n",
      "2019.09.29 : 14 articles are done\n",
      "2019.09.30 : 7 articles are done\n",
      "2019.09. : 459 articles are available\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Crawling Start \n",
    "\n",
    "news = pd.DataFrame()\n",
    "\n",
    "for m in range(0,len(date_dict)) :\n",
    "    month = list(date_dict.keys())[m]\n",
    "    total_title_cnt = 0\n",
    "\n",
    "    for d in range(0,len(list(date_dict.values())[m])):\n",
    "        date = month + format(d+1).zfill(2)\n",
    "\n",
    "        whole_source = \"\"\n",
    "        for page_number in range(0, 10):  \n",
    "            base_url = 'https://search.naver.com/search.naver?where=news&query=' + keyword + '&sm=tab_opt&sort=0&photo=0&field=0&reporter_article=&pd=3&mynews=0&refresh_start=0&related=0'\n",
    "            url = base_url + '&ds=' + date + '&de=' + date + '&start='+ str(page_number*10+1)\n",
    "            res = req.get(url)\n",
    "            whole_source = whole_source + res.text\n",
    "\n",
    "        soup = bs(whole_source, 'html.parser')\n",
    "        title_tmp = soup.select('li > dl > dt > a._sp_each_title')\n",
    "        \n",
    "        title = [i.text for i in title_tmp]\n",
    "        \n",
    "        search = [\"KIA\",\"kia\",\"tigers\",\"TIGERS\",\"기아\",\"타이거즈\"]\n",
    "        title_list = []\n",
    "        for i in range(0,len(search)):\n",
    "            title_can = [test for test in title if search[i] in test]\n",
    "            title_list = title_list + title_can\n",
    "        \n",
    "        title = set(title_list)\n",
    "        print(date,':',len(title), 'articles are done')\n",
    "\n",
    "        news_tmp = pd.DataFrame([[ date, title]],  columns=['date', 'title'])\n",
    "        news = pd.concat([news, news_tmp])\n",
    "        total_title_cnt = total_title_cnt + len(title)\n",
    "\n",
    "    print(month,':', total_title_cnt, 'articles are available')\n",
    "    print(\"---------------------------------------------------\")\n",
    "\n",
    "file_csv = 'newstitle_' + keyword + '.csv'\n",
    "file_txt = 'newstitle_' + keyword + '.txt'\n",
    "\n",
    "news.to_csv(file_csv, index=False)\n",
    "news.to_csv(file_txt, index=False, header=True, sep=\"\\t\")\n",
    "    \n",
    "# Crawling End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>cPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.04.01</td>\n",
       "      <td>{'깜짝 7K KIA 황인준에게 두번째 선발 기회가 올까', 'KIA 불펜 희망으로...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.04.02</td>\n",
       "      <td>{'KIA 주간전망-호랑이 군단, 라이벌 삼성·키움과 정면대결', 'KIA 이명기의...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.04.03</td>\n",
       "      <td>{\"또 다시 미뤄진 KIA '괴물루키' 김기훈 프로 데뷔 선발승, 삼성전 6이닝 4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019.04.04</td>\n",
       "      <td>{\"KIA 선발 양현종 '역투'\", \"KIA 최형우, 적시타 '달려'\", 'KIA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019.04.05</td>\n",
       "      <td>{\"KIA 이명기 '이게 홈런의 맛'\", \"'이명기 결승 홈런' KIA, 키움 꺾고...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  cPOS\n",
       "0  2019.04.01  {'깜짝 7K KIA 황인준에게 두번째 선발 기회가 올까', 'KIA 불펜 희망으로...     1\n",
       "1  2019.04.02  {'KIA 주간전망-호랑이 군단, 라이벌 삼성·키움과 정면대결', 'KIA 이명기의...     0\n",
       "2  2019.04.03  {\"또 다시 미뤄진 KIA '괴물루키' 김기훈 프로 데뷔 선발승, 삼성전 6이닝 4...     0\n",
       "3  2019.04.04  {\"KIA 선발 양현종 '역투'\", \"KIA 최형우, 적시타 '달려'\", 'KIA ...     1\n",
       "4  2019.04.05  {\"KIA 이명기 '이게 홈런의 맛'\", \"'이명기 결승 홈런' KIA, 키움 꺾고...     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:\\\\Users\\\\JYW\\\\OneDrive - 연세대학교 (Yonsei University)\\\\정해용\\\\2020 1학기\\\\딥러닝응용\\\\project')\n",
    "\n",
    "dataset = pd.read_csv('newstitle_타이거즈.csv')\n",
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
